---
title: 20241028/LLM
published: 2024-12-07
updated: 2024-10-29T00:00:00+09:00

entry-id: tag:blog.hatena.ne.jp,2013:blog-Nisaki-6801883189054638642-6802418398300292648
author: Nisaki
edited: 2024-12-13T09:17:10+09:00
tags:
  - grancing_abstracts
  - discipline
---

<p>Buyl, M., Rogiers, A., Noels, S., Dominguez-Catena, I., Heiter, E., Romero, R., ... &amp; De Bie, T. (2024). Large Language Models Reflect the Ideology of their Creators. arXiv preprint arXiv:2410.18417.<br />https://doi.org/10.48550/arXiv.2410.18417</p>
<blockquote>
<p>大規模言語モデル（LLM）は、自然言語を生成するために膨大な量のデータで学習され、テキストの要約や質問応答などのタスクを実行できるようにする。 これらのモデルは、ChatGPTのような人工知能（AI）アシスタントに普及しており、すでに人間が情報にアクセスする方法において影響力のある役割を果たしている。 しかし、LLMの振る舞いは、その設計、訓練、使用方法によって異なる。 本論文では、異なるLLMやLLMにアクセスする言語間で示されるイデオロギー的スタンスに顕著な多様性があることを明らかにする。 これは、最近の世界史で物議を醸した著名人について、英語と中国語の両方で記述するよう、一般的なLLMの多様なパネルに促すことによって行う。 生成された記述に反映されている道徳的評価を特定し分析することで、同じLLMが英語と中国語でどのように反応するかの間に一貫した規範的差異を見出す。 同様に、地政学的紛争における著名なアクターについて、西洋と非西洋のLLMの間に規範的な不一致があることも明らかにした。 さらに、一般に仮説とされている欧米のモデル間の政治的目標の相違は、インクルージョン、社会的不平等、政治的スキャンダルに関する規範の大きな相違に反映されている。 我々の結果は、LLMのイデオロギー的スタンスは、しばしばその作成者の世界観を反映していることを示している。 このことは、LLMをイデオロギー的に「不偏不党」にすることを目的とした技術的・規制的努力にまつわる重要な懸念を提起し、政治的道具化のリスクをもたらす。</p>
</blockquote>
<p>---</p>
<blockquote class="twitter-tweet" data-conversation="none" data-lang="ja">
<p dir="ltr" lang="ja">LLMの思想的立場は、モデルの作成者の世界観を反映していて、中立でないことが明らかになった。<br /><br />OpenAIのモデルは国際的な組織や福祉国家に対して懐疑的な姿勢を示す。<br /><br />一方、他の西洋のモデルはよりリベラルで人権重視の立場だ。<br /><br />知らず知らずのうちに使い手が影響を受けてしまうかもしれない。 <a href="https://t.co/3glOWABFkb">https://t.co/3glOWABFkb</a> <a href="https://t.co/45Z8wORLlG">pic.twitter.com/45Z8wORLlG</a></p>
— K.Ishi@生成AIの産業応用 (@K_Ishi_AI) <a href="https://twitter.com/K_Ishi_AI/status/1850718600296112437?ref_src=twsrc%5Etfw">2024年10月28日</a></blockquote>
<p>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p>
<p>Linegar, M., Kocielnik, R., &amp; Alvarez, R. M. (2023). Large language models and political science. Frontiers in Political Science, 5, 1257092.<br />https://doi.org/10.48550/arXiv.2412.06864</p>
<p>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p>
<blockquote>
<p>近年、大規模言語モデル（LLM）は、選挙予測、感情分析、政策影響評価、誤報検出などの政治学のタスクに広く採用されている。 一方で、LLMがこの分野にどのような革命をもたらすかを体系的に理解することも急務となっている。 本研究では、計算機科学と政治学にまたがる学際的な研究者チームである我々が、LLMを計算政治科学に統合する包括的な理解を進めるために、Political-LLMと名付けた最初の原則的なフレームワークを提示する。 具体的には、まず、既存の研究を政治学と計算方法論の2つの視点に分類する基本的な分類法を紹介する。 特に、政治学の観点からは、予測・生成タスクの自動化、行動ダイナミクスのシミュレーション、反事実生成のようなツールによる因果推論の改善におけるLLMの役割を強調し、計算論的観点からは、政治的文脈に合わせたLLMのデータ準備、微調整、評価手法の進歩を紹介する。 主要な課題と将来の方向性を明らかにし、分野固有のデータセットの開発、偏りと公平性の争点への対処、人間の専門知識の導入、計算政治科学特有の要件に沿った評価基準の再定義を強調する。 Political-LLMは、政治科学における人工知能の、情報に基づいた倫理的でインパクトのある利用を促進するための、研究者のためのガイドブックとしての役割を果たすことを目指している。</p>
</blockquote>
<p> </p>
